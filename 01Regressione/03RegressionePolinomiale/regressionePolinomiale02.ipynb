{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12330a09-b902-4dc9-99df-853d2e5a376f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ccasadei/corso-ia/blob/master/01Regressione/03RegressionePolinomiale/regressionePolinomiale02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e9d6a-f8a4-4c0f-b9a3-b21c5aad80c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regressione polinomiale\n",
    "## Esercizio 2\n",
    "**Author: Cristiano Casadei**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209ad2eb-d26d-477c-a6ae-ffdd93f8c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb30463-f142-4ce4-9fe9-c151df62d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello in overfitting già al grado 3\n",
      "TRAIN --- MSE: 8.551849227877048e-23  - R2: 1.0\n",
      "TEST ---- MSE: 11703.304270563356  - R2: -125.96148346681773\n"
     ]
    }
   ],
   "source": [
    "# importiamo il solito dataset al completo\n",
    "dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\",\n",
    "                      sep=\"\\s+\",\n",
    "                      names=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PRATIO\", \"B\", \"LSTAT\", \"MEDV\"])\n",
    "\n",
    "# associamo ad X i valori di tutte le colonne meno MEDV\n",
    "# associamo ad Y i valori di output\n",
    "X = dataset.drop(\"MEDV\", axis=1).values\n",
    "Y = dataset[\"MEDV\"].values\n",
    "\n",
    "# suddividiamo il dataset in due dataset, uno di training ed uno di test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# genero le feature per i set di training e di test con grado 3 cha abbiamo visto essere in overfitting\n",
    "polyfeatures = PolynomialFeatures(degree=3)\n",
    "X_train_poly = polyfeatures.fit_transform(X_train)\n",
    "X_test_poly = polyfeatures.transform(X_test)\n",
    "\n",
    "# standardizzo le feature polinomiali dei due set\n",
    "ss = StandardScaler()\n",
    "X_train_poly_std = ss.fit_transform(X_train_poly)\n",
    "X_test_poly_std = ss.transform(X_test_poly)\n",
    "\n",
    "# eseguo la regressione lineare multipla,\n",
    "lRegr = LinearRegression()\n",
    "lRegr.fit(X_train_poly_std, Y_train)\n",
    "Y_pred_train = lRegr.predict(X_train_poly_std)\n",
    "Y_pred_test = lRegr.predict(X_test_poly_std)\n",
    "\n",
    "# visualizzo i risultati\n",
    "mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "r2_train = r2_score(Y_train, Y_pred_train)\n",
    "mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "r2_test = r2_score(Y_test, Y_pred_test)\n",
    "print(\"Modello in overfitting già al grado 3\")\n",
    "print(\"TRAIN --- MSE:\", mse_train, \" - R2:\", r2_train)\n",
    "print(\"TEST ---- MSE:\", mse_test, \" - R2:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7370fb-1f5d-4dfd-9199-2dde61bff3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usiamo la regolarizzazione L1 con Lasso\n",
      "Alpha: 0.0001\n",
      "TRAIN --- MSE: 2.4562994734900663  - R2: 0.9697055210529494\n",
      "TEST ---- MSE: 18.25775087927996  - R2: 0.8019336178218156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.476e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.229e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.064e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001\n",
      "TRAIN --- MSE: 2.5711574331938922  - R2: 0.9682889339959955\n",
      "TEST ---- MSE: 15.079450152158856  - R2: 0.8364129209220448\n",
      "Alpha: 0.01\n",
      "TRAIN --- MSE: 4.259481193002115  - R2: 0.9474661926530423\n",
      "TEST ---- MSE: 10.233757276194671  - R2: 0.8889806694599018\n",
      "Alpha: 0.1\n",
      "TRAIN --- MSE: 10.943459778507362  - R2: 0.8650301335623246\n",
      "TEST ---- MSE: 11.953011433548603  - R2: 0.8703296070566818\n",
      "Alpha: 1.0\n",
      "TRAIN --- MSE: 22.15011357124247  - R2: 0.7268141948891318\n",
      "TEST ---- MSE: 19.100207088500934  - R2: 0.7927943621376277\n",
      "Alpha: 10.0\n",
      "TRAIN --- MSE: 81.08076319065403  - R2: 0.0\n",
      "TEST ---- MSE: 92.2020720754774  - R2: -0.00023989625398068704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e+01, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# preparo un array con i vari valori di lambda che vogliamo provare\n",
    "# NOTA: \"alpha is the new lambda\"... almeno in SciKitLearn...\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1., 10.]\n",
    "\n",
    "print(\"Usiamo la regolarizzazione L1 con Lasso\")\n",
    "for alpha in alphas:\n",
    "    # uso il modello Lasso che utilizza la regolarizzazione L1\n",
    "    model = Lasso(alpha=alpha)\n",
    "    model.fit(X_train_poly_std, Y_train)\n",
    "\n",
    "    # faccio la predizione sia su train che su test, per confrontare i risultati\n",
    "    # e capire come si evolve l'overfitting\n",
    "    Y_pred_train = model.predict(X_train_poly_std)\n",
    "    Y_pred_test = model.predict(X_test_poly_std)\n",
    "\n",
    "    # visualizzo i risultati\n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    r2_train = r2_score(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    r2_test = r2_score(Y_test, Y_pred_test)\n",
    "    print(\"Alpha:\", alpha)\n",
    "    print(\"TRAIN --- MSE:\", mse_train, \" - R2:\", r2_train)\n",
    "    print(\"TEST ---- MSE:\", mse_test, \" - R2:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21d3dc2-5a42-4a3a-b3e4-354fc7437033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usiamo la regolarizzazione L2 con Ridge\n",
      "Alpha: 0.0001\n",
      "TRAIN --- MSE: 0.2503980980443792  - R2: 0.9969117446828221\n",
      "TEST ---- MSE: 184.51331576016992  - R2: -1.0016641237991912\n",
      "Alpha: 0.001\n",
      "TRAIN --- MSE: 0.5515880624912244  - R2: 0.993197053890647\n",
      "TEST ---- MSE: 49.99729448776958  - R2: 0.4576120956317735\n",
      "Alpha: 0.01\n",
      "TRAIN --- MSE: 1.076127784077183  - R2: 0.9867277052937111\n",
      "TEST ---- MSE: 25.462605572534905  - R2: 0.7237728677574682\n",
      "Alpha: 0.1\n",
      "TRAIN --- MSE: 1.902225102476955  - R2: 0.9765391317542973\n",
      "TEST ---- MSE: 15.681778479046741  - R2: 0.8298786553720907\n",
      "Alpha: 1.0\n",
      "TRAIN --- MSE: 3.261859967499045  - R2: 0.9597702360074105\n",
      "TEST ---- MSE: 11.20656069846295  - R2: 0.8784273622265394\n",
      "Alpha: 10.0\n",
      "TRAIN --- MSE: 6.0694366920297655  - R2: 0.9251433206448978\n",
      "TEST ---- MSE: 10.240505693312349  - R2: 0.8889074603021713\n"
     ]
    }
   ],
   "source": [
    "print(\"Usiamo la regolarizzazione L2 con Ridge\")\n",
    "for alpha in alphas:\n",
    "    # uso il modello Ridge che utilizza la regolarizzazione L2\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train_poly_std, Y_train)\n",
    "\n",
    "    # faccio la predizione sia su train che su test, per confrontare i risultati\n",
    "    # e capire come si evolve l'overfitting\n",
    "    Y_pred_train = model.predict(X_train_poly_std)\n",
    "    Y_pred_test = model.predict(X_test_poly_std)\n",
    "\n",
    "    # visualizzo i risultati\n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    r2_train = r2_score(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    r2_test = r2_score(Y_test, Y_pred_test)\n",
    "    print(\"Alpha:\", alpha)\n",
    "    print(\"TRAIN --- MSE:\", mse_train, \" - R2:\", r2_train)\n",
    "    print(\"TEST ---- MSE:\", mse_test, \" - R2:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d70874-6793-4f8b-aa9d-dd84302faf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usiamo entrambe le regolarizzazioni con ElasticNet\n",
      "Alpha: 0.0001\n",
      "TRAIN --- MSE: 2.459462505093104  - R2: 0.9696665101768973\n",
      "TEST ---- MSE: 17.940892666466294  - R2: 0.8053710050602771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.711e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001\n",
      "TRAIN --- MSE: 2.617563243128191  - R2: 0.9677165934295262\n",
      "TEST ---- MSE: 13.841321280173894  - R2: 0.8498445701961469\n",
      "Alpha: 0.01\n",
      "TRAIN --- MSE: 4.762397978930565  - R2: 0.9412635279747895\n",
      "TEST ---- MSE: 10.095068335777468  - R2: 0.8904852149462649\n",
      "Alpha: 0.1\n",
      "TRAIN --- MSE: 10.094327399066271  - R2: 0.8755028073017717\n",
      "TEST ---- MSE: 11.939901080809053  - R2: 0.8704718326875042\n",
      "Alpha: 1.0\n",
      "TRAIN --- MSE: 20.722913241578446  - R2: 0.7444164013003873\n",
      "TEST ---- MSE: 19.50835365378116  - R2: 0.7883666473485488\n",
      "Alpha: 10.0\n",
      "TRAIN --- MSE: 66.83301748568552  - R2: 0.1757228859756319\n",
      "TEST ---- MSE: 75.31698600782204  - R2: 0.1829353443493491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.934e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+02, tolerance: 2.870e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "print(\"Usiamo entrambe le regolarizzazioni con ElasticNet\")\n",
    "for alpha in alphas:\n",
    "    # uso il modello ElasticNet che utilizza entrambe le regolarizzazioni\n",
    "    # NOTA: il parametro l1_ratio indica a quale regolarizzazione dare più importanza\n",
    "    # 0.5 -> sia L1 che L2 sono utilizzate con lo stesso peso nella regolarizzazione complessiva\n",
    "    # >0.5 -> L1 ha un peso maggiore nella regolarizzazione complessiva\n",
    "    # <0.5 -> L1 ha un peso minore nella regolarizzazione complessiva\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=0.5)\n",
    "    model.fit(X_train_poly_std, Y_train)\n",
    "\n",
    "    # faccio la predizione sia su train che su test, per confrontare i risultati\n",
    "    # e capire come si evolve l'overfitting\n",
    "    Y_pred_train = model.predict(X_train_poly_std)\n",
    "    Y_pred_test = model.predict(X_test_poly_std)\n",
    "\n",
    "    # visualizzo i risultati\n",
    "    mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    r2_train = r2_score(Y_train, Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
    "    r2_test = r2_score(Y_test, Y_pred_test)\n",
    "    print(\"Alpha:\", alpha)\n",
    "    print(\"TRAIN --- MSE:\", mse_train, \" - R2:\", r2_train)\n",
    "    print(\"TEST ---- MSE:\", mse_test, \" - R2:\", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a6601-12fa-4472-ae23-7a14ce754b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
